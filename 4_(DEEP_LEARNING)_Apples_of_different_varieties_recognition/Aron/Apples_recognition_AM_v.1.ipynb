{"cells":[{"cell_type":"markdown","metadata":{"id":"SzL1JOteJdkF"},"source":["# Setting Google environment and importing libraries"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":225,"status":"ok","timestamp":1677156738252,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"P7NY-YgQ3PJR"},"outputs":[],"source":["# connecting google drive to google colab\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1677156738617,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"qJp7dR1e2iuu"},"outputs":[],"source":["# importing libraries\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import os"]},{"cell_type":"markdown","metadata":{"id":"eneqr4o1JlIx"},"source":["# Exploratory"]},{"cell_type":"markdown","metadata":{"id":"vvxIud_cJoB0"},"source":["### Check image size"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1677158853125,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"u_1JFb0t_ug0","outputId":"0c5d63b8-e5ef-4109-b628-e9ab15bcb451"},"outputs":[{"data":{"text/plain":["['Apple_B', 'Apple_C', 'Apple_F']"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["# list of folders with pictures\n","list_of_apples = os.listdir('drive/MyDrive/Apples/')\n","list_of_apples"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1677158854558,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"ajUqVyEKb99X","outputId":"c62dcca7-0e88-45b0-e2a8-a1292938c486"},"outputs":[{"data":{"text/plain":["['drive/MyDrive/Apples/Apple_B',\n"," 'drive/MyDrive/Apples/Apple_C',\n"," 'drive/MyDrive/Apples/Apple_F']"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["# creating a list of folders\n","folder_path = 'drive/MyDrive/Apples/'\n","list_of_folders = [folder_path + apple_kind for apple_kind in list_of_apples]\n","list_of_folders"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8443,"status":"ok","timestamp":1677156747054,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"QsN2Dess6GWg","outputId":"965e53d0-8ab8-43fd-cff7-3e942234e57a"},"outputs":[{"data":{"text/plain":["shape\n","(258, 320, 3)    666\n","(322, 480, 3)    336\n","dtype: int64"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# loop through all the apples and check its shape\n","# loop takes care about changing BGR to RGB\n","# loop flatten the picture\n","picture_data_C = {}\n","folder_path_C = 'drive/MyDrive/Apples/Apple_C'\n","for pic in os.listdir(folder_path_C):\n","  pic_path = os.path.join(folder_path_C, pic)\n","  img = cv2.imread(pic_path)\n","  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  shape = img_rgb.shape\n","  pixels = img_rgb.flatten()\n","  picture_data_C[pic] = {'shape': shape, 'pixels': pixels}\n","\n","# changing picture data dictionary to a data frame\n","df_C = pd.DataFrame.from_dict(picture_data_C, orient=\"index\").sort_index().reset_index().rename(columns={\"index\": \"name\"})\n","df_C.value_counts(subset=\"shape\")"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9263,"status":"ok","timestamp":1677156756295,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"4dU4sFqhDRFC","outputId":"c548386e-d5c7-425c-c751-e97a25c6dbe1"},"outputs":[{"data":{"text/plain":["shape\n","(322, 480, 3)    740\n","dtype: int64"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# loop through all the apples and check its shape\n","# loop takes care about changing BGR to RGB\n","# loop flatten the picture\n","picture_data_B = {}\n","folder_path_B = 'drive/MyDrive/Apples/Apple_B'\n","for pic in os.listdir(folder_path_B):\n","  pic_path = os.path.join(folder_path_B, pic)\n","  img = cv2.imread(pic_path)\n","  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  shape = img_rgb.shape\n","  pixels = img_rgb.flatten()\n","  picture_data_B[pic] = {'shape': shape, 'pixels': pixels}\n","\n","# changing picture data dictionary to a data frame\n","df_B = pd.DataFrame.from_dict(picture_data_B, orient=\"index\").sort_index().reset_index().rename(columns={\"index\": \"name\"})\n","df_B.value_counts(subset=\"shape\")"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13584,"status":"ok","timestamp":1677156769874,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"_uJ_9EJeFf0p","outputId":"08b2e556-ac69-4379-cda2-d0ab6430f007"},"outputs":[{"data":{"text/plain":["shape\n","(258, 320, 3)    2030\n","dtype: int64"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# loop through all the apples and check its shape\n","# loop takes care about changing BGR to RGB\n","# loop flatten the picture\n","picture_data_F = {}\n","folder_path_F = 'drive/MyDrive/Apples/Apple_F'\n","for pic in os.listdir(folder_path_F):\n","  pic_path = os.path.join(folder_path_F, pic)\n","  img = cv2.imread(pic_path)\n","  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  shape = img_rgb.shape\n","  pixels = img_rgb.flatten()\n","  picture_data_F[pic] = {'shape': shape, 'pixels': pixels}\n","\n","# changing picture data dictionary to a data frame\n","df_F = pd.DataFrame.from_dict(picture_data_F, orient=\"index\").sort_index().reset_index().rename(columns={\"index\": \"name\"})\n","df_F.value_counts(subset=\"shape\")"]},{"cell_type":"markdown","metadata":{"id":"wSbVgLPAH6h9"},"source":["**First problem with dataset is that images have different shape** <br>\n","* There is over 1000 samples with different shape\n","* There is a need to do a resamplig to reseize them to one common shape\n","* While resizing it needs to be consider aspect ratio and color\n","* Color is especially important, because it allows to differenciate apples easily than by its shape\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AuC2MEVuVSOz"},"source":["**Some of interpolation methods while resizing an image:** <br>\n","https://www.geeksforgeeks.org/image-resizing-using-opencv-python/"]},{"cell_type":"markdown","metadata":{"id":"fa1viiywWHNV"},"source":["# Resizing and storing into single dataframe"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":199,"status":"ok","timestamp":1677158266571,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"Z1nj5iyWWIyf"},"outputs":[],"source":["def store_pictures_info_in_dataframe(folder_path:str,\n","                                     fixed_size:tuple,\n","                                     apple_class:int) -> pd.DataFrame:\n","  \n","  picture_data = {}\n","\n","  for pic in os.listdir(folder_path):\n","    pic_path = os.path.join(folder_path, pic)\n","    img = cv2.imread(pic_path)\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    \n","    # Resize the image to the fixed size\n","    # interpolation=cv2.INTER_AREA works well with shrinking images\n","    img_resized = cv2.resize(src=img_rgb,\n","                             dsize=fixed_size,\n","                             interpolation=cv2.INTER_AREA)\n","    \n","    shape = img_resized.shape\n","    pixels = img_resized.flatten()\n","    picture_data[pic] = {'shape': shape, 'pixels': pixels}\n","\n","  df = pd.DataFrame.from_dict(picture_data, orient=\"index\").sort_index().reset_index().rename(columns={\"index\": \"name\"})\n","  df[\"apple_class\"] = apple_class\n","\n","  return df"]},{"cell_type":"code","execution_count":65,"metadata":{"executionInfo":{"elapsed":36114,"status":"ok","timestamp":1677159393103,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"Qg-3VpGkbNX1"},"outputs":[],"source":["dfs = {}\n","for apple_class, path in enumerate(list_of_folders):\n","  df_name = f\"df_{apple_class}\"\n","  df = store_pictures_info_in_dataframe(folder_path=path,\n","                                        fixed_size=(256, 256),\n","                                        apple_class=apple_class)\n","  dfs[df_name] = df"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":221,"status":"ok","timestamp":1677159431274,"user":{"displayName":"Data Science","userId":"17535823268101108586"},"user_tz":-60},"id":"BJm6kBZXe5Eq","outputId":"7f33346c-4f88-4d43-daaf-b353b00dae42"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-a929bcc6-a2a9-4827-bce7-820d5ae7e936\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>shape</th>\n","      <th>pixels</th>\n","      <th>apple_class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>102red applee00901102.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[57, 58, 56, 53, 53, 48, 58, 61, 57, 61, 64, 5...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>103red applee00916103.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[34, 43, 46, 43, 43, 49, 38, 47, 47, 38, 47, 5...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>107red applee01001107.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[50, 57, 48, 47, 50, 45, 54, 58, 50, 57, 61, 4...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>108red applee01006108.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[30, 47, 56, 36, 48, 52, 33, 41, 47, 35, 45, 5...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>109red applee01021109.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[33, 45, 56, 40, 47, 53, 37, 40, 48, 39, 44, 5...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3767</th>\n","      <td>scene07801.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[45, 38, 41, 61, 55, 56, 69, 66, 64, 69, 68, 6...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3768</th>\n","      <td>scene07821.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[48, 55, 48, 65, 69, 61, 74, 74, 64, 76, 76, 7...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3769</th>\n","      <td>scene07841.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[43, 50, 45, 61, 66, 61, 64, 65, 58, 70, 71, 6...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3770</th>\n","      <td>scene07861.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[40, 47, 42, 59, 64, 58, 64, 65, 58, 70, 71, 6...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3771</th>\n","      <td>scene07881.png</td>\n","      <td>(256, 256, 3)</td>\n","      <td>[40, 47, 42, 59, 64, 58, 64, 65, 58, 70, 71, 6...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3772 rows Ã— 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a929bcc6-a2a9-4827-bce7-820d5ae7e936')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a929bcc6-a2a9-4827-bce7-820d5ae7e936 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a929bcc6-a2a9-4827-bce7-820d5ae7e936');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                           name          shape  \\\n","0     102red applee00901102.png  (256, 256, 3)   \n","1     103red applee00916103.png  (256, 256, 3)   \n","2     107red applee01001107.png  (256, 256, 3)   \n","3     108red applee01006108.png  (256, 256, 3)   \n","4     109red applee01021109.png  (256, 256, 3)   \n","...                         ...            ...   \n","3767             scene07801.png  (256, 256, 3)   \n","3768             scene07821.png  (256, 256, 3)   \n","3769             scene07841.png  (256, 256, 3)   \n","3770             scene07861.png  (256, 256, 3)   \n","3771             scene07881.png  (256, 256, 3)   \n","\n","                                                 pixels  apple_class  \n","0     [57, 58, 56, 53, 53, 48, 58, 61, 57, 61, 64, 5...            0  \n","1     [34, 43, 46, 43, 43, 49, 38, 47, 47, 38, 47, 5...            0  \n","2     [50, 57, 48, 47, 50, 45, 54, 58, 50, 57, 61, 4...            0  \n","3     [30, 47, 56, 36, 48, 52, 33, 41, 47, 35, 45, 5...            0  \n","4     [33, 45, 56, 40, 47, 53, 37, 40, 48, 39, 44, 5...            0  \n","...                                                 ...          ...  \n","3767  [45, 38, 41, 61, 55, 56, 69, 66, 64, 69, 68, 6...            2  \n","3768  [48, 55, 48, 65, 69, 61, 74, 74, 64, 76, 76, 7...            2  \n","3769  [43, 50, 45, 61, 66, 61, 64, 65, 58, 70, 71, 6...            2  \n","3770  [40, 47, 42, 59, 64, 58, 64, 65, 58, 70, 71, 6...            2  \n","3771  [40, 47, 42, 59, 64, 58, 64, 65, 58, 70, 71, 6...            2  \n","\n","[3772 rows x 4 columns]"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.concat(dfs.values(), ignore_index=True).reset_index()\n","df"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM91OfnI3TkqpC0yJ5pauyU","mount_file_id":"1hZK3k5WgT8X2LZ9HGtOoAeO1wbEPstDw","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
